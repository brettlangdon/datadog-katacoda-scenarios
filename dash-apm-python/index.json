{
  "title": "Pinpointing Microservice Bottlenecks in Python with Datadog APM",
  "description": "As software moves to microservices and containers, the need for better tooling to debug our systems grows.\n\nIn this workshop, we'll introduce distributed tracing as a method to gain visibility and insight into these distributed applications.\n\nTraces allow us to see units of work, as they pass across our subsystems. By incorporating traces with logs and metrics, we can see performance bottlenecks, verify legacy system changes, and deploy confidently into complex environments.\n\nWe'll instrument a few Python microservices with the Datadog Agent, and see how distributed traces can be used in the real world, to get better insight into the health of your systems.",
  "details": {
    "steps": [
      {
        "title": "Introduction",
        "text": "step_1.md"
      },
      {
        "title": "Get traces flowing",
        "text": "step_2.md"
      },
      {
        "title": "Enable trace analytics",
        "text": "step_3.md"
      },
      {
        "title": "Adding custom metadata",
        "text": "step_4.md"
      },
      {
        "title": "Introducing errors",
        "text": "step_5.md"
      },
      {
        "title": "Introducing latencies",
        "text": "step_6.md"
      },
      {
        "title": "Adding manual spans",
        "text": "step_7.md"
      },
      {
        "title": "Enable trace and logs",
        "text": "step_8.md"
      },
      {
        "title": "Enable process agent",
        "text": "step_9.md"
      }
    ],
    "intro": {
      "text": "intro.md",
      "courseData": "background.sh",
      "code": "foreground.sh"
    },
    "finish": {
      "text": "finish.md"
    }
  },
  "environment": {
    "uilayout": "editor-terminal",
    "uieditorpath": "/tracing-workshop",
    "showdashboard": true,
    "dashboards": [
      {
        "name": "Frontend",
        "port": 5000
      }
    ]
  },
  "backend": {
    "imageid": "ubuntu",
    "reuseConnection": true,
    "livetime": "3h",
    "environmentsprotocol": "http",
    "port": 5000
  }
}
